---
title: "Association Rule Mining for Predicting NFL Game Winners and Spread Covers"
output: html_document
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```
## Introduction

This analysis looked at a dataset of NFL games, which was found on Kaggle at:

https://www.kaggle.com/tobycrabtree/nfl-scores-and-betting-data

The goal was to use association rule mining to find relationships between variables around NFL games and

1)  Whether the favored team wins the game

2)  Whether the favored team covers the pre-game betting point spread

With the Supreme Court ruling this past year that allows states to legalize sports gambling, there has already been a huge uptick in the number of states where it has been adopted.  This analysis will look at over 9,000 NFL game outcomes from 1979-2018 to identify trends on potential factors that could influence the outcome of a game.

## The Data

```{r include=FALSE}
games <- read.csv("C:/Users/Lucy's House/Desktop/Class/BZAN 552 - Data Mining/Final Projects/Case 2 - NFL Scores/spreadspoke_scores.csv")
teams <- read.csv("C:/Users/Lucy's House/Desktop/Class/BZAN 552 - Data Mining/Final Projects/Case 2 - NFL Scores/nfl_teams.csv")
options(scipen=999)
stadiums <- read.csv("C:/Users/Lucy's House/Desktop/Class/BZAN 552 - Data Mining/Final Projects/Case 2 - NFL Scores/nfl_stadiums.csv")
```

This dataset consists of 12,400 NFL games spanning the 1966 season through the midway point (November 15, 2018) of the current 2018 season with different attritubes for each game.  The following is a complete listing, along with a brief description (where necessary) for every variable:

schedule_date - date of game

schedule_season - the year of the football season in which the game took place

schedule_week - the week of the season for the game; also includes playoff round descriptions

team_home - name of home team

team_away - name of away team

stadium - name of stadium where game took place

team_favorite_id - 3-digit ID for team that was favored going into the game; also can be PICK if there was no favorite

spread_favorite - how much the favorite was favored to win by

over_under_line - the total number of expected points to be scored between the two teams

weather_detail - a text field with various details on the weather conditions for the game that day

weather_temperature - temperature during the game

weather_wind_mph - wind (in mph) during the game

weather_humidity - humidity during the game

score_home - how many points the home team scored

score_away - how many points the away team scored

stadium_neutral - whether the game was at a neutral site or not (TRUE/FALSE)

schedule_playoff - whether the game was a playoff game (TRUE/FALSE) 

A second dataset contains information on teams that will be used to convert team names into team ID numbers so that the identifiers for teams will be consistent and can be matched up accordingly.  The variables in the team dataset are:

team_name - the name of the team

team_short_short - nickname/short name for team

team_id - unique 3-digit team ID

team_id_pfr - alternate 3-digit team ID

team_conference - conference of team (AFC/NFC)

team_division - division of team

team_conference_pre2002 - conference team was in prior to realignment in 2002

team_division_pre2002 - division team was in prior to realignment in 2002

The third dataset contains information on each stadium in which the games are played and is made up of the following variables:

stadium_name - name of stadium

stadium_location - city/state of stadium

stadium_open - which year the stadium opened

stadium_close - which year the stadium closed

stadium_type - what type of stadium it is (indoor/outdoor/retractable)

stadium_address - address of stadium

stadium_weather_station_code

stadium_weather_type - type of weather typical for the stadium (cold/dome/moderate/warm)

stadium_capacity - fan capacity for stadium

stadium_surface - type of playing surface in stadium (FieldTurf/Grass)

STATION 

LATITUDE

LONGITUDE

ELEVATION

## Approach

With this large amount of data, it was important to decide on a focused direction for how to approach it.  This analysis attempted to find insights around 3 questions:

1)  What associations could be found for games in which the favorite won?

2)  What associations could be found for games in which the favorite covered the point spread?

3)  What associations could be found for games where the final scoring margin fell outside the predicted margins?

### Cleaning & Formatting the Data

Before assocation rule mining could begin, several steps needed to be taken to clean and format the data to get it into the proper format for analysis.  Here is a brief look at the original data, along with the data types for each variable:

```{r, echo=FALSE}
games$schedule_week <- toupper(games$schedule_week)
str(games)
```

After thinking through our approach and deciding which variables made the most sense to use, several were immediately removed - schedule_date, over_under_line, weather_detail, and weather_humidity.

The schedule_date was going to provide too much detail than what we needed since it is the exact day on which the game took place.  We kept the schedule_season so that we still had the year variable, in case there were trends over a period of time.

Since we were not concerned in this analysis with the prediction of how many points would be scored and were focused more on the winners/favored team heading into a game, we removed over_under_line.

The weather_detail would have required quite a bit of cleanup since it is just a text field with some key facts about the weather.  Many of these are also captured in the weather_temperature, weather_wind_mph, and weather_humidity variables - which are broken out in a cleaner numeric format.  These were the ones we kept, while eliminating the weather_detail column.

Over 32% of the rows had missing data in the weather_humidity column.  With this amount of missing data and the reasoning that this variable would probably have little (or no) impact on the analysis at the end, we removed it.

```{r}
sum(table(games$weather_humidity)[1])/nrow(games)
```

```{r}
games$schedule_date <- NULL
games$over_under_line <- NULL
games$weather_detail <- NULL
games$weather_humidity <- NULL
```

The next bit of cleanup required removing rows in which there is not a favorite team listed.  You can see that there are 2,601 of them, with many occurring in the earlier years.  This is likely due to the fact that the betting/favorite data was not as widespread 40-50 year ago and probably just not able to be collected.  Since we were looking for associations on whether or not the favorite won, this was a necessary piece of information for our analysis, and we were not be able to use rows that do not contain it.  

```{r}
table(games$team_favorite_id)
```

Once these were removed, we found that we had very few games for the 1966-1978 seasons (only 1 from 1966-77 and 10 in 1978).  Therefore, we went ahead and narrowed down our dataset to only the 1979-2018 seasons.  We also went ahead and removed rows with any other missing information. 

```{r, echo=FALSE}
teams <- teams[,c('team_name', 'team_id')]
games <- games[games$team_favorite_id %in% c(as.character(teams$team_id), "PICK"),]
games <- games[games$schedule_season > 1978,]
games <- games[complete.cases(games),]
```

This step reduced the dataset to 9,405 rows.  

The next step required converting the team names in the team_home and team_away columns into the 3-digit team ID numbers.  Since this was the format that the team_favorite_id column was, we needed to get them into the same format so that we could easily identify which team was the favorite/underdog and whether the favorite was the home team or away team.  We did this by utilizing the 'teams' dataset referenced in the Data section above.

```{r, echo=FALSE}
games <- merge(games, teams, by.x = "team_home", by.y = "team_name")
colnames(games)[14] <- "home_team_id"
games <- merge(games, teams, by.x = "team_away", by.y = "team_name")
colnames(games)[15] <- "away_team_id"
games$team_home <- games$team_away <- NULL
games$home_team_favorite <- ifelse(as.character(games$team_favorite_id) == as.character(games$home_team_id), "Yes", "No")
games$team_underdog_id <- ifelse(games$home_team_favorite == "Yes", as.character(games$away_team_id), as.character(games$home_team_id))
rm(teams)
games$home_team_id <- NULL
games$away_team_id <- NULL
```

We then needed to do some work to get the predicted game results and actual game results into a better format.  When listing the spread, it is typically done by listing the numbers with a negative value, as you can see in the spread_favorite column.  However, practically speaking, if we want to know how much the favorite was predicted to win by, it makes more sense to convert it to a positive value instead, which we did.  We also re-labeled the column to fav_margin_predicted to make it clearer that this was the value the favorite was expected to win by.

Since we had the scores for the home and away teams and knew which one was the favorite, we also calculated the favorite's actual margin of victory and difference between what was predicted vs. what actually happened.  An important note here is that if a favorite was expected to win but did not, then their actual margin and margin difference would be negative.  For example, in Week 3 in 2011, Arizona was favored by 3 going into the game against Seattle, but they actually ended up losing by 3. Therefore, their actual margin of "victory" was -3, since they lost as a favorite.  The difference was -6, since it was a 6-point (3 to -3) that the the predicted margin missed by.

```{r, echo=FALSE}
games$fav_margin_predicted <- games$spread_favorite*(-1)
games$spread_favorite <- NULL
games$fav_margin_actual <- ifelse(games$home_team_favorite=="Yes", (games$score_home - games$score_away), (games$score_away - games$score_home))
games$fav_margin_difference <- games$fav_margin_actual - games$fav_margin_predicted
```

```{r, echo=FALSE}
games[c('schedule_season', 'schedule_week', 'team_favorite_id', 'home_team_favorite', 'team_underdog_id', 'score_home', 'score_away', 'fav_margin_predicted', 'fav_margin_actual', 'fav_margin_difference')][games$schedule_week=="3" & games$schedule_season==2011 & games$team_favorite_id=="ARI",]
```

From this information, we also calculated two more variables for whether or not the favorite won and whether or not the favorite covered the spread, which was the focus of our analysis for questions 1 and 2.

```{r, echo=FALSE}
games$favorite_win <- ifelse(games$fav_margin_actual > 0, "Yes", "No")
games$favorite_beat_spread <- ifelse(games$fav_margin_actual > games$fav_margin_predicted, "Yes", "No")
games$fav_margin_actual <- NULL
```

At this point, we now also added in two of the variables around the stadium in which the game was played - stadium_type and stadium_surface - which were found in the 'stadiums' dataset.

```{r, echo=FALSE}
stadiums <- stadiums[,c('stadium_name', 'stadium_type', 'stadium_surface')]
games <- merge(games, stadiums, by.x = "stadium", by.y = "stadium_name")
rm(stadiums)
games$stadium_type <- as.character(games$stadium_type)
games$stadium_surface <- as.character(games$stadium_surface)
```

While we were not focused on the over/under as far as predicted points scored, we thought it might be interesting to see if higher-scoring games or higher-scoring games were more prone to upsets.  Therefore, we added the score_home and score_away variables for a new points_scored variable to account for this.

```{r, echo=FALSE}
games$points_scored <- games$score_home + games$score_away
games$score_home <- games$score_away <- NULL
```

Since we were going to convert all of the variables to factors before running association rules, we binned the numeric variables into ranges that would more easily convert to factors - including weather_temperature, weather_wind_mph, fav_margin_predicted, fav_margin_difference, and points_scored.

```{r, echo=FALSE}
games.orig <- games
temp.breaks <- seq(-10, 100, by=10)
games$weather_temperature <- cut(games$weather_temperature, temp.breaks)
wind.breaks <- seq(0, 40, by=10)
games$weather_wind_mph <- cut(games$weather_wind_mph, wind.breaks)
predict.margin.breaks <- c(-1, 3, 7, 14, 27)
games$fav_margin_predicted <- cut(games$fav_margin_predicted, predict.margin.breaks)
difference.breaks <- seq(-56, 56, by=7)
games$fav_margin_difference <- cut(games$fav_margin_difference, difference.breaks)
point.breaks <- seq(0, 112, by=14)
games$points_scored <- cut(games$points_scored, point.breaks)
```

Finally, the last step of the data cleaning process was to convert the remaining variables that were not yet factors into the factor data type.

```{r, echo=FALSE}
games$schedule_season <- as.factor(games$schedule_season)
games$schedule_week <- as.factor(games$schedule_week)
games$stadium_neutral <- as.factor(games$stadium_neutral)
games$schedule_playoff <- as.factor(games$schedule_playoff)
games$home_team_favorite <- as.factor(games$home_team_favorite)
games$team_underdog_id <- as.factor(games$team_underdog_id)
games$favorite_win <- as.factor(games$favorite_win)
games$favorite_beat_spread <- as.factor(games$favorite_beat_spread)
games$stadium_type <- as.factor(games$stadium_type)
games$stadium_surface <- as.factor(games$stadium_surface)
```

After all of the cleaning steps and re-formatting, the following is an outline of the dataset we used for the analyis:

```{r}
str(games)
```

### Question 1 - Associations for Games in Which the Favorite Won 

The first question we looked at was discovering any potential associations between whether or not the favored team going into the game actually won.  In order to do this, we removed the two variables - fav_beat_spread and fav_margin_difference - since the information on whether or not the favorite won is also contained in these variables. Leaving them in would have confused the results since there would obviously have been strong relationships between them.

```{r, include=FALSE}
games.fav.won <- games
games.fav.won$favorite_beat_spread <- games.fav.won$fav_margin_difference <- NULL
library(arules)
library(dplyr)
```

When we initially ran the 'apriori' algorithm in the 'arules' package, we looked at all rules generated and sorted by lift since 1,963 rules were generated.  We also lowered the confidence parameter to 0.5, since the default is 0.8, which gave us a broader set of rules to look at.

```{r}
rules.wins <- apriori(games.fav.won,
                          control = list(verbose=F),
                          parameter = list(minlen=2, supp=0.1, conf=0.5)) %>% sort(by="lift")
summary(rules.wins)
inspect(rules.wins[1:10])
```

One thing we observed when we looked at the top ten rules above was that many of the rules were associations that had nothing to do with whether or not the favored team won the game.  Therefore, we needed to narrow down our results to only view rules that included whether or not the favorite won. 

```{r}
rules.wins <- apriori(games.fav.won,
                 control = list(verbose=F),
                 parameter = list(minlen=2, supp=0.1, conf=0.5),
                 appearance = list(rhs=c("favorite_win=Yes", "favorite_win=No"),
                                   default="lhs")) %>% sort(by="lift")
summary(rules.wins)
inspect(rules.wins[1:10])
```

There were two new observations we made here.  The first was that the number of rules had been reduced to 259, which is a smaller number than the original 1,963 rules.  The second was that while this number was smaller, we still observed some redundancy in the results.  This means that a rule may show up that is a subset of another rule, meaning that the larger rule is not really adding any more information.  However, we addressed the redundancy to reduce the number of rules either further to a total of 19.

```{r}
subset.matrix <- is.subset(rules.wins, rules.wins)
redundant <- colSums(subset.matrix) > 1
rules.wins.reduced <- rules.wins[!redundant] 
summary(rules.wins.reduced)
inspect(rules.wins.reduced[1:6])
```

You can now see the top handful of rules associated with a favored team winning the game.  

The first is if the predicted margin of victory is 7-14 points.  This should not be too surprising to see this rule with the strongest lift, because in the NFL, being more than a touchdown favorite means that the odds are pretty good that you will win the game.  You can also see this relationship illustrated in the following chart, where the winning percentage of the favorite increases the more they are favored going into a game - which also makes complete logical sense.

```{r, echo=FALSE}
games$favorite_win <- ifelse(games$favorite_win=="Yes", 1, 0)
Fav.Margin <- c(mean(games$favorite_win), mean(as.numeric(as.character(games$favorite_win[games$fav_margin_predicted=="(-1,3]"]))), mean(as.numeric(as.character(games$favorite_win[games$fav_margin_predicted=="(3,7]"]))), mean(as.numeric(as.character(games$favorite_win[games$fav_margin_predicted=="(7,14]"]))), mean(as.numeric(as.character(games$favorite_win[games$fav_margin_predicted=="(14,27]"]))))
Fav.Margin <- round(Fav.Margin, 2)

text(x = barplot(Fav.Margin, names.arg = c("All Games", "0-3", "4-7", "8-14", "15+"), ylab = "% of Games Where Favorite Wins", xlab = "Predicted Margin of Victory", ylim = c(0, 1)), y = Fav.Margin, label = Fav.Margin, pos = 3)
```

The second rule is if the stadium surface is field turf.  This one requires a bit more thought, but since turf is more immune to weather and elements than grass, this could point to an "equal playing field" benefiting the favored team.  This makes sense because there is less opportunity for unexpected factors to influence game results and add extra variation to a game which could open up the door to an underdog winning.  You can see that while it is only a slight difference, the favorite wins in games played on turf is slightly higher than the average win rate for favorites across all games, which is also the same as the win rate on grass (66%).

```{r, echo=FALSE}
Stadium_Surface <- c(mean(games$favorite_win), mean(as.numeric(as.character(games$favorite_win[games$stadium_surface=="FieldTurf"]))), mean(as.numeric(as.character(games$favorite_win[games$stadium_surface=="Grass"]))))
Stadium_Surface <- round(Stadium_Surface, 2)

text(x = barplot(Stadium_Surface, names.arg = c("All Games", "FieldTurf", "Grass"), ylab = "% of Games Where Favorite Wins", xlab = "Stadium Surface", ylim = c(0, 1)), y = Stadium_Surface, label = Stadium_Surface, pos = 3)
```

The third rule is unsurprising, since home teams tend to win more than away teams because of home-field advantage.  Coupling a home team also being favored would then really put the odds in their corner.  This relationship is illustrated below.

```{r, echo=FALSE}
Home.Field <- c(mean(games$favorite_win), mean(as.numeric(as.character(games$favorite_win[games$home_team_favorite=="No"]))), mean(as.numeric(as.character(games$favorite_win[games$home_team_favorite=="Yes"]))))
Home.Field <- round(Home.Field, 2)

text(x = barplot(Home.Field, names.arg = c("All Games", "Away", "Home"), ylab = "% of Games Where Favorite Wins", xlab = "Favorite Is Away or Home Team", ylim = c(0, 1)), y = Home.Field, label = Home.Field, pos = 3)
```

The fourth rule is similar to Rule 1, just with a lower impact, since the expected margin of victory is lower.  

The 5th rule indicates that higher scoring games also favor the favorites, since the average number of points scored in a game is 41.8.  This could also make sense, because higher scoring games likely indicate more possessions by each team, which would mean there is more chance over the course of the game for the favored team to show they are the better team.  If you plot the results (below), however, it appears as though this relationship may not necessarily hold at the higher levels of points being scored.  It could be that the top scoring groups have smaller sample sizes so the comparison may not be as valid, or it could be that this is just not a linear relationship and instead, it peaks out in the 43-56 point range.

```{r, echo=FALSE}
Points_Scored <- c(mean(games$favorite_win), mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(0,14]"]))), mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(14,28]"]))), mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(28,42]"]))), mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(42,56]"]))),
mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(56,70]"]))), mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(70,84]"]))), mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(84,98]"]))), mean(as.numeric(as.character(games$favorite_win[games$points_scored=="(98,112]"]))))
Points_Scored <- round(Points_Scored, 2)

text(x = barplot(Points_Scored, names.arg = c("All", "0-14", "15-28", "29-42", "43-56", "57-70", "71-84", "85-98", "99-112"), ylab = "% of Games Where Favorite Wins", xlab = "Total Points Scored in Game", ylim = c(0, 1.1)), y = Points_Scored, label = Points_Scored, pos = 3)
```

The 6th rule around weather could also be similar to the 2nd rule with the field turf.  A temperature range of 60-70 degrees, is pretty "ideal" weather for a football game, meaning there is less opportunity for really cold temperatures (and/or snow) or really hot temperatures (which can take additional, unexpected physical tolls on players) to throw additional variation into a game for an underdog team.  However, if you plot this relationship, it is not completely clear if it would actually hold across the spectrum.  Part of the variation could also be due to the small sample sizes at some of the temperature ranges.

```{r, echo=FALSE}
Temperature <- c(mean(games$favorite_win), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(-10,0]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(0,10]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(10,20]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(20,30]"]))),
mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(30,40]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(40,50]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(50,60]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(60,70]"]))),
mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(70,80]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(80,90]"]))), mean(as.numeric(as.character(games$favorite_win[games$weather_temperature=="(90,100]"]))))
Temperature <- round(Temperature, 2)

text(x = barplot(Temperature, names.arg = c("All", "-10-0", "0-10", "10-20", "20-30", "30-40", "40-50", "50-60", "60-70", "70-80", "80-90", "90-100"), ylab = "% of Games Where Favorite Wins", xlab = "Temperature", ylim = c(0, 1)), y = Temperature, label = Temperature, pos = 3)
```

Looking at the overall results for Question 1, you can also see that the support and confidence are high enough for these top rules that they occur fairly frequently and the associations hold true a good majority of the time.

### Question 2 - Associations for Games in Which the Favorite Covered the Spread

After looking for assocations between variables and whether or not the favored team won the game, the analysis was taken a step further.  Question 2 asks if there are any assocations between variables and whether the favored team covered the projected point spread.  In simple terms, the spread is how much the favored team is expected to win by.  So which associations could be found when a team did or did not win by at least the expected margin of victory?

In sports gambling terms, this is an important next step, because the spread is how many bets are made.  As we saw in the first question, there is a strong relationship between the expected margin of victory (the spread) and whether or not the favorite won the game.  This makes complete sense, because if a team is expected to win by 30 points, that means the belief is that the favorite is a significantly better team than their opponent.  Compare this situation to a game where a team is only favored by 1 point.  The predicted odds of the favorite winning are only slightly better than a coin flip, so you would expect the win probabilities to match up accordingly.  That is why most sports betting is not done around just picking winners, but instead, is focused on picking whether or not a team ends up over or under their predicted margin of victory.

Having said that, we used almost the same variables as in Question 1.  The only difference was that we took out the favorite_win variable and substituted it with favorite_beat_spread, since that was now our focus.

```{r, include=FALSE}
games.fav.spread <- games
games.fav.spread$fav_margin_difference <- games.fav.spread$favorite_win <- NULL
```

Just as before, we ran the 'apriori' algorithm after we lowered the confidence parameter to 0.5 to generate a large number of rules (1,843) to initially review.

```{r}
rules.fav.spread <- apriori(games.fav.spread,
                            control = list(verbose=F),
                            parameter = list(minlen=2, supp=0.1, conf=0.5)) %>% sort(by="lift")
summary(rules.fav.spread)
inspect(rules.fav.spread[1:10])
```

Next, we narrowed down our list of rules to only rules with associations to whether or not the favorite team covered the spread (achieved at least the minimum predicted margin of victory).

```{r}
rules.fav.spread <- apriori(games.fav.spread,
                            control = list(verbose=F),
                            parameter = list(minlen=2, supp=0.1, conf=0.5),
                      appearance = list(rhs=c("favorite_beat_spread=Yes", "favorite_beat_spread=No"),
                                   default="lhs")) %>% sort(by="lift")
summary(rules.fav.spread)
inspect(rules.fav.spread[1:10])
```

The rule list shrunk to 171 rules, but you can see from reviewing the top 10 by lift that there was still some redudancy we needed to address again.  Once we did that, we were left with our final rule set of 17.

```{r}
subset.matrix <- is.subset(rules.fav.spread, rules.fav.spread)
redundant <- colSums(subset.matrix) > 1
rules.fav.spread.reduced <- rules.fav.spread[!redundant] 
summary(rules.fav.spread.reduced)
inspect(rules.fav.spread.reduced[1:6])
```

Of these 17 rules, only 6 of them had a lift greater than 1.  If you take a closer look at them, some of them make sense but others are harder to interpret.

For the first rule, it says there is an assocation between the favorite not beating the spread and if the temperature is between 70-80 degrees.  On the surface, this is hard to say why this might be the case, so we will plot it to see if that will help identify any potential trends.

```{r, echo=FALSE}
games$favorite_beat_spread <- ifelse(games$favorite_beat_spread=="Yes", 1, 0)
Temperature <- c(mean(games$favorite_beat_spread), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(-10,0]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(0,10]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(10,20]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(20,30]"]))),
mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(30,40]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(40,50]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(50,60]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(60,70]"]))),
mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(70,80]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(80,90]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$weather_temperature=="(90,100]"]))))
Temperature <- round(Temperature, 2)

text(x = barplot(Temperature, names.arg = c("All", "-10-0", "0-10", "10-20", "20-30", "30-40", "40-50", "50-60", "60-70", "70-80", "80-90", "90-100"), ylab = "% of Games Where Favorite Beats Spread", xlab = "Temperature", ylim = c(0, 1)), y = Temperature, label = Temperature, pos = 3)
```

Unfortunately, the chart does not seem to shed any further light but it does visually display the association rule we see.  The percentage of games in which the favorite beats the spread hovers right at or around the average of 47% for most temperature ranges from 20-90 degrees.  You can see the percentages dip down to 45% in the 70-80 degree range, but it is hard to tell why this might be the case and probably requires further investigation and potentially more data.

The second rule is also less obvious, because it is saying that favorites are less likely to cover the spread of games played indoors.  Below is a plot to illustrate this point.

```{r, echo=FALSE}
Stadium.Type <- c(mean(games$favorite_beat_spread), mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_type=="indoor"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_type=="outdoor"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_type=="retractable"]))))
Stadium.Type <- round(Stadium.Type, 2)

text(x = barplot(Stadium.Type, names.arg = c("All", "Indoor", "Outdoor", "Retractable Roof"), ylab = "% of Games Where Favorite Beats Spread", xlab = "Stadium Type", ylim = c(0, 1)), y = Stadium.Type, label = Stadium.Type, pos = 3)
```

Once again, the evidence seems weak, but this could also be why the lift is barely above 1.  Even though it was identifed as a rule, it is not a strong one.

The third rule is finally one that makes a lot of sense.  It says that teams favored by 3 points or fewer are less likely to cover.  As mentioned previously, when the predicted margin is this small, the prognosticators are essentially saying the game is close to a coin flip, so it makes sense that this uncertainty around who will win would also decrease the percentage of teams that cover.  After all, you first have to win in order to also beat the spread.

```{r, echo=FALSE}
Fav.Margin <- c(mean(games$favorite_beat_spread), mean(as.numeric(as.character(games$favorite_beat_spread[games$fav_margin_predicted=="(-1,3]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$fav_margin_predicted=="(3,7]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$fav_margin_predicted=="(7,14]"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$fav_margin_predicted=="(14,27]"]))))
Fav.Margin <- round(Fav.Margin, 2)

text(x = barplot(Fav.Margin, names.arg = c("All Games", "0-3", "4-7", "8-14", "15+"), ylab = "% of Games Where Favorite Beats Spread", xlab = "Predicted Margin of Victory", ylim = c(0, 1)), y = Fav.Margin, label = Fav.Margin, pos = 3)
```

One other interesting thing you will notice from the chart, but which was not picked up in the association rules mining is that there is also a dropoff where the predicted margin of victory becomes greater than 14 (more than 2 TDs).  This is also not a surprise, because even though a team might be heavily favored, it can be difficult even for good teams to beat bad teams by huge margins.  If the game is not in doubt late, it is not unusual for teams to play backups or score additional points/stats in "garbage" time that do not affect the outcome of the game, but can keep point margins from being too high.

The 4th rule is also one that makes sense, because it says that when a favorite is the away team, it is also more difficult for them to cover.  As established in Question 1, this is due to home-field advantage, which also has an association with the overall winner as well.

```{r, echo=FALSE}
Home.Field <- c(mean(games$favorite_beat_spread), mean(as.numeric(as.character(games$favorite_beat_spread[games$home_team_favorite=="No"]))), mean(as.numeric(as.character(games$favorite_beat_spread[games$home_team_favorite=="Yes"]))))
Home.Field <- round(Home.Field, 2)

text(x = barplot(Home.Field, names.arg = c("All Games", "Away", "Home"), ylab = "% of Games Where Favorite Beats Spread", xlab = "Favorite Is Away or Home Team", ylim = c(0, 1)), y = Home.Field, label = Home.Field, pos = 3)
```

The 5th rule is a confusing one, since it is saying that there is an association between the favorite not covering the spread and the stadium surface being blank or unknown in the data.  There is probably not much that can be further gleaned here, so we will just look at it visually.

```{r, echo=FALSE}
Stadium_Surface <- c(mean(games$favorite_beat_spread), mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_surface==""]))),
mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_surface=="FieldTurf"]))),
mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_surface=="Grass"]))))
Stadium_Surface <- round(Stadium_Surface, 2)

text(x = barplot(Stadium_Surface, names.arg = c("All Games", "Unknown", "FieldTurf", "Grass"), ylab = "% of Games Where Favorite Beats Spread", xlab = "Stadium Surface", ylim = c(0, 1)), y = Stadium_Surface, label = Stadium_Surface, pos = 3)
```

The last and final rule says that if the stadium is not at a neutral site, there is an association with the favorite not covering the spread.  Going back to the idea of home-field advantage, this rule also makes sense.  If it's not a neutral field, then one team is going to be at a small disadvantage just based on this fact alone.  Since most NFL teams will play half their games away, the league is set up that half the time, you are working against this built in disadvantage.  When the game is on a neutral field, the playing field is more "level", so you would expect the better team - as predicted - would win (and cover the predicted margin) more frequently.

```{r, echo=FALSE}
Neutral <- c(mean(games$favorite_beat_spread), mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_neutral=="TRUE"]))),
mean(as.numeric(as.character(games$favorite_beat_spread[games$stadium_neutral=="FALSE"]))))
Neutral <- round(Neutral, 2)

text(x = barplot(Neutral, names.arg = c("All Games", "Neutral", "Non-Neutral"), ylab = "% of Games Where Favorite Beats Spread", xlab = "Neutral Field", ylim = c(0, 1)), y = Neutral, label = Neutral, pos = 3)
```

The rules in Question 2 appear to be weaker than the rules in Question 1 based on their lower supports and confidence.  The frequency that the top 6 rules have ranges only from 10-25% - except for the Neutral Stadium rule, which is at 53%.  On the other hand, the lift is also the lowest of the 6 for this one.  On confidence, these values are also lower than in the first part.  They are all still over 0.5 - meaning that the association holds true over half the time, however, none of them are over 56%.  However, in gambling, just like in predicting stock movement, even an incremental increase over 50% (random guessing) can have very tangible results.

### Question 3 - Associations for Differences in Actual and Predicted Point Spreads

Now that we had taken the first two steps into this analysis, the last part of the association rules mining was to see if there were any associations with the differences in the actual and predicted point spreads.  What we attempted to do here was find cases where the final margin of the game was significantly different from what was predicted (both high and low) and see if there were any associations that could be drawn in those cases.  If there were insights that could be learned here, it would allow people to identify potential factors that make games very hard to predict (so they probably shouldn't even try) or find games that might be "easier" to predict, meaning their final results will end up fairly close to the pre-game predicted margin.

```{r, include=FALSE}
games.differences <- games
games.differences$favorite_win <- games.differences$favorite_beat_spread <- NULL
```

Similary to how we did before, we removed the favorite_win and favorite_beat_spread variables since their associations are too strong with fav_margin_differnce and don't teach us anything. We then ran the 'apriori' algorithm after we lowered the confidence parameter to 0.5 to generate a large number of rules (1,212) to initially review.

```{r}
rules.diffs <- apriori(games.differences,
                          control = list(verbose=F),
                          parameter = list(minlen=2, supp=0.1, conf=0.5)) %>% sort(by="lift")
summary(rules.diffs)
inspect(rules.diffs[1:10])
```

Once again, we narrowed down our list of rules to only rules with associations to the point margin diferences between the actual and predicted margins by the favorites.

```{r}
rules.diffs <- apriori(games.differences,
                            control = list(verbose=F),
                            parameter = list(minlen=2, supp=0.001, conf=0.5),
                      appearance = list(rhs=c("fav_margin_difference=(-56,-49]", "fav_margin_difference=(-49,-42]", "fav_margin_difference=(-42,-35]", "fav_margin_difference=(-35,-28]", "fav_margin_difference=(-28,-21]", "fav_margin_difference=(-21,-14]", "fav_margin_difference=(-14,-7]", "fav_margin_difference=(-7,0]", "fav_margin_difference=(0,7]", "fav_margin_difference=(7,14]", "fav_margin_difference=(14,21]", "fav_margin_difference=(21,28]", "fav_margin_difference=(28,35]", "fav_margin_difference=(35,42]", "fav_margin_difference=(42,49]", "fav_margin_difference=(49,56]"),
                                   default="lhs")) %>% sort(by="lift")
summary(rules.diffs)
inspect(rules.diffs[1:5])
```

One thing we quickly saw was that we had to lower our parameters even further to get any rules returned.  We kept the confidence at a minimum of 0.5, because we wanted to make sure that the associations were true at least half the time - which is the meaning behind the value of 0.5  However, we lowered support all the way to 0.001.  Support indicates how often the rule appears in the dataset, so by reducing this value, we reduced the minimum number of times it had to appear and would be careful on how we interpreted it.  However, at least this gave us some results that we could review.  Once we removed redundant rules, we were down to 113 rules.

```{r}
subset.matrix <- is.subset(rules.diffs, rules.diffs)
redundant <- colSums(subset.matrix) > 1
rules.diffs.reduced <- rules.diffs[!redundant] 
summary(rules.diffs.reduced)
inspect(rules.diffs.reduced[1:5])
```

If you look at the top 5, you can quickly see that even though the lift numbers are very high (and the confidence too in many cases), the support/number of times it appears in the dataset is very low.  In the top 5 rules, all of them appear only 10 or 11 times (0.1% of the time).  This could very well indicate this rule is really just noise and there would be concern in extrapolating these results over a broader population.

The conclusion from this analysis is that this dataset contains enough variables to draw some solid associations between higher level questions, such as whether the favored team wins or not, or even if they cover the spread.  However, the strength of the rules breaks down when you go deeper into trying to determine associations between the differences in actual and predicted point margins.

In some instances, these insights might be helpful, but to draw any deeper conclusions, more granular data would be needed - if it even exists.  After all, if it was that easy to predict point margins between pre-game spreads and the actual final scores, places like Las Vegas would not stay in business for very long!